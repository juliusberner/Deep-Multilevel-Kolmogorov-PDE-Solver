{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilevel Monte Carlo Solver (Tensorflow v.1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages, reset the computational graph, start interactive Tensorflow session and set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Parameter of the PDE (constant coefficient parabolic equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('PDE-Parameter'):\n",
    "    d=100 #dimension\n",
    "    mu=tf.zeros((1,d),name='Mu') #(alternativ: tf.zeros((1,d),name='Mu') for explicit solution, 0.2*tf.ones((1,d),name='Mu'))\n",
    "    sigma=tf.multiply(1/d**0.5,tf.ones((d,d)),name='Sigma') #Sigma TRANSPOSED #(alternativ: np.eye(d), 0.5*np.random.randint(-2,2,(d,d)), np.random.uniform(-2,2,(d,d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Parameter of the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=1.0 #time, where the solution is evaluated\n",
    "a=0.0 \n",
    "b=1.0 #approx. the solution of the PDE in [a,b]^d\n",
    "l_max=0 #2^(l_max) is the number of time steps in the finest level\n",
    "l_min=0 #2^(l_min) is the number of time steps in the coarsest level\n",
    "#n_hidlayer_fine=1\n",
    "#n_neurons_fine=[16]\n",
    "n_hidlayer=5 #number of hidden layers for the neural nets\n",
    "n_neurons=[d,256,128,64,16] #number of neurons for the hidden layers\n",
    "K=16 #batch/sample multiplicator for the different levels\n",
    "n_valid=10000 #number of samples for validation of the expected value/loss\n",
    "n_acc=50 #number of samples for measuring the accuracy\n",
    "valid_steps=500 #every valid_steps the loss is computed\n",
    "#start_learn_rate_coarse=1e-3 #starting learning rate of the gradient descent\n",
    "start_lr=1e-3\n",
    "decay_steps=500 #learning rate decays exponentially \n",
    "w_initializer=tf.contrib.layers.variance_scaling_initializer() #initializer of the weights (alternativ: tf.contrib.layers.xavier_initializer(uniform=True) for Sigmoid, tf.constant_initializer(0), tf.contrib.layers.variance_scaling_initializer() for ReLu, tf.truncated_normal_initializer(0,1))\n",
    "#weight_initializer_fine=tf.contrib.layers.variance_scaling_initializer()\n",
    "b_initializer=tf.zeros_initializer() #initializer of the biases (alternativ: tf.zeros_initializer(), tf.constant_initializer(0.01) for ReLu)\n",
    "#bias_initializer_fine=tf.zeros_initializer()\n",
    "activation=tf.nn.sigmoid #activation function (alternativ: tf.nn.sigmoid, tf.nn.elu, tf.nn.relu, tf.nn.tanh)\n",
    "adam_eps=1e-7 #epsilon of the Adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for defining a neuronal network, attaching summaries to the Tensors (for TensorBoard visualization), feeding with data, calculating the loss and optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(var): \n",
    "    with tf.variable_scope('Summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('Average', mean)\n",
    "        tf.summary.histogram('Histogram', var)\n",
    "\n",
    "def phi(x,lvl):\n",
    "    with tf.variable_scope('Euler-Scheme'):\n",
    "        with tf.variable_scope('Fine_Realization'):\n",
    "            N_fine=tf.constant(2**lvl,name='Steps_fine',dtype=tf.int32) \n",
    "            h_fine=tf.divide(T,tf.cast(N_fine,tf.float32),name='Step-Size_fine')\n",
    "            dw_fine=tf.random_normal(shape=[N_fine,tf.shape(x)[0],d],mean=0.0,stddev=tf.sqrt(h_fine),name='DW')\n",
    "            count=tf.constant(0,name='Count')\n",
    "            def scheme_fine(i,realisation):\n",
    "                realisation+=mu*h_fine+tf.matmul(dw_fine[i,:,:],sigma)\n",
    "                return [i+1,realisation]\n",
    "            _, y_fine=tf.while_loop(lambda i,realisation: i<N_fine, scheme_fine, loop_vars=[count,x],name='Euler-Loop_fine')\n",
    "        if lvl==l_min:\n",
    "            phi=tf.reduce_sum(y_fine**2, axis=1, keepdims=True, name='Phi')\n",
    "            return phi\n",
    "        else:\n",
    "            with tf.variable_scope('Coarse_Realization'):\n",
    "                N_coarse=tf.constant(2**(lvl-1),name='Steps_coarse',dtype=tf.int32)\n",
    "                h_coarse=tf.divide(T,tf.cast(N_coarse,tf.float32),name='Step-Size_coarse')\n",
    "                dw_coarse=dw_fine[0::2,:,:]+dw_fine[1::2,:,:]\n",
    "                def scheme_coarse(i,realisation):\n",
    "                    realisation+=mu*h_coarse+tf.matmul(dw_coarse[i,:,:],sigma)\n",
    "                    return [i+1,realisation]                 \n",
    "                _, y_coarse=tf.while_loop(lambda i,realisation: i<N_coarse, scheme_coarse, loop_vars=[count,x],name='Euler-Loop_coarse')\n",
    "            phi=tf.subtract(tf.reduce_sum(y_fine**2, axis=1, keepdims=True),tf.reduce_sum(y_coarse**2, axis=1, keepdims=True),name='Phi')\n",
    "            return phi\n",
    "            \n",
    "def nn(input_layer, num_hidlayer, num_neurons, level, weight_initializer, bias_initializer, start_learn_rate, training):\n",
    "    name_suffix=str(level)\n",
    "    with tf.variable_scope('Network_'+name_suffix):           \n",
    "        with tf.variable_scope('Target'):\n",
    "            is_validation=tf.placeholder(tf.bool,name='Is_Validation') #boolean for batch normalization and input decision\n",
    "            z=tf.cond(is_validation,lambda: tf.placeholder(tf.float32,[None,1],name='Z-Input'),lambda: phi(input_layer,level),name='Network-Target')\n",
    "        with tf.variable_scope('Normalization'):\n",
    "            prev_output=input_layer-(a+b)/2 #shift to zero mean for better performance\n",
    "        for n in range(num_hidlayer):\n",
    "            with tf.variable_scope('Hidden_Layer%d' %(n+1)):\n",
    "                prev_output=tf.contrib.layers.fully_connected(prev_output,num_neurons[n],activation_fn=activation,normalizer_fn=tf.contrib.layers.batch_norm,normalizer_params={'is_training':training,'updates_collections':'updates'},weights_initializer=weight_initializer)\n",
    "                #prev_output=tf.contrib.layers.fully_connected(prev_output,num_neurons[n],activation_fn=activation,weights_initializer=weight_initializer,biases_initializer=bias_initializer)\n",
    "                variable_summaries(prev_output)\n",
    "        with tf.variable_scope('Output_Layer'):\n",
    "            output=tf.contrib.layers.fully_connected(prev_output,1,activation_fn=None,normalizer_fn=None,weights_initializer=weight_initializer,biases_initializer=bias_initializer)\n",
    "            variable_summaries(output)\n",
    "        with tf.variable_scope('Losses'):\n",
    "            #delta=tf.clip_by_value(z-output,-100.0,100.0) #clipped difference between output and labels \n",
    "            #loss=tf.reduce_mean(delta**2, name='Loss') #mean squared error (alternativ: loss=tf.losses.mean_squared_error(z,output))\n",
    "            loss=tf.reduce_mean((z-output)**2, name='Loss')\n",
    "            tf.summary.scalar('Loss-Summary', loss)\n",
    "    with tf.name_scope('Train_'+name_suffix):            \n",
    "        global_step=tf.Variable(0, trainable=False, name='Global_Step') #counts the number of training steps\n",
    "        learn_rate=tf.train.exponential_decay(start_learn_rate, global_step,decay_steps, 0.99, staircase=True, name='Learn_Rate')\n",
    "        optimizer=tf.train.AdamOptimizer(learn_rate,epsilon=1e-7, name='Adam') #tf.train.RMSPropOptimizer(learn_rate, centered=True, name='RMSProp') #tf.train.AdagradOptimizer(learn_rate, name='Adagrad') #MomentumOptimizer(learn_rate,0.5,name='Momentum',use_nesterov=True) #(alternativ: lambda lr: tf.train.AdamOptimizer(lr,epsilon=1e-7, name='Adam'))\n",
    "        var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Network_'+name_suffix)\n",
    "        update_ops = tf.get_collection('updates', scope='Network_'+name_suffix)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            training=optimizer.minimize(loss,global_step=global_step,var_list=var_list,name='Minimizer')\n",
    "        summaries=tf.get_collection(tf.GraphKeys.SUMMARIES, scope='Network_'+name_suffix)\n",
    "        merged=tf.summary.merge(summaries, name='Merged') #run all summaries at once\n",
    "    return output, z\n",
    "\n",
    "def uniform_input():\n",
    "    batch_size=tf.placeholder(tf.int32,shape=[],name='Batchsize')\n",
    "    return tf.random_uniform([batch_size,d],minval=a,maxval=b,name='Xi-Input')\n",
    "\n",
    "def build_model():\n",
    "    with tf.variable_scope('Input'):\n",
    "        is_training=tf.placeholder(tf.bool,name='Is_Training') #boolean for batch normalization and input decision\n",
    "        nn_input=tf.cond(is_training,lambda: uniform_input(),lambda: tf.placeholder(tf.float32,[None,d],name='X-Input'),name='Network-Input')\n",
    "    out=[nn(nn_input,n_hidlayer,n_neurons,l, w_initializer, b_initializer, start_lr, is_training) for l in range(l_min,l_max+1)]\n",
    "    nn_outputs=[lst[0] for lst in out]\n",
    "    phi_outputs=[lst[1] for lst in out]\n",
    "    with tf.variable_scope('Accuracy'):\n",
    "        u_MC=tf.add_n(phi_outputs,name='U_MC')\n",
    "        u_MC_mean=tf.reduce_mean(u_MC,name='U_MC_Mean')\n",
    "        u_real=tf.placeholder(tf.float32,[None,1],name='U_Real') #Input for the actual solution\n",
    "        u_approx=tf.add_n(nn_outputs,name='U_Approximation') #Function for evaluation of the approximation (of the function u(T,x))\n",
    "        abs_diff=tf.abs(u_approx-u_real,name='Absolute-Error')\n",
    "        max_error=tf.reduce_max(abs_diff,name='Max-Error')\n",
    "        tf.summary.scalar('Max_Error-Summary', max_error)\n",
    "        l2_error=tf.sqrt(tf.reduce_mean(abs_diff**2)*(b-a)**d,name='L2-Error')\n",
    "        tf.summary.scalar('L2_Error-Summary', l2_error)\n",
    "        summaries_acc=tf.get_collection(tf.GraphKeys.SUMMARIES, scope='Accuracy')\n",
    "        merged_acc=tf.summary.merge(summaries_acc, name='Merged_Acc') #run all summaries at once\n",
    "\n",
    "def valid_accuracy_data(num_validation,num_accuracy):\n",
    "    dictionary={'Input/Is_Training:0': True, 'Input/Network-Input/Batchsize:0': num_accuracy}\n",
    "    accuracy_data=[sess.run('Input/Network-Input/Merge:0',feed_dict=dictionary)]\n",
    "    dictionary['Input/Network-Input/Batchsize:0']=num_validation\n",
    "    dictionary.update({'Network_'+str(l)+'/Target/Is_Validation:0': False for l in range(l_min,l_max+1)})\n",
    "    fetch=['Input/Network-Input/Merge:0']\n",
    "    fetch.append(['Network_'+str(l)+'/Target/Network-Target/Merge:0' for l in range(l_min,l_max+1)])\n",
    "    validation_data=sess.run(fetch,feed_dict=dictionary)\n",
    "    dictionary['Input/Is_Training:0']=False    \n",
    "    del dictionary['Input/Network-Input/Batchsize:0']\n",
    "    MC_mean=np.empty((num_accuracy,1))\n",
    "    for sample in range(num_accuracy):\n",
    "        dictionary.update({'Input/Network-Input/X-Input:0': np.tile(accuracy_data[0][sample],(5000,1))})\n",
    "        MC_mean[sample]=sess.run('Accuracy/U_MC_Mean:0',feed_dict=dictionary)    \n",
    "    accuracy_data.append(MC_mean)\n",
    "    return validation_data, accuracy_data\n",
    "\n",
    "#less input batchsize for higher levels!!!\n",
    "    \n",
    "def trainNN(level,n_iterations,validation_data,accuracy_data,batch_sizes):\n",
    "    name_suffix=str(level)\n",
    "    scope='Network_'+name_suffix+'/'\n",
    "    scope_train='Train_'+name_suffix+'/'\n",
    "    scope_target=scope+'Target/'\n",
    "    scope_z_target=scope_target+'Network-Target/'\n",
    "    valid_dictionary={'Input/Network-Input/X-Input:0': validation_data[0], scope_z_target+'Z-Input:0': validation_data[1][level], 'Input/Is_Training:0': False, scope_target+'Is_Validation:0': True}\n",
    "    accuracy_dictionary={'Input/Network-Input/X-Input:0': accuracy_data[0], 'Input/Is_Training:0': False, 'Accuracy/U_Real:0': accuracy_data[1]}\n",
    "    glob_iterations=sess.run(scope_train+'Global_Step:0')\n",
    "    for iteration in range(glob_iterations,glob_iterations+n_iterations): #for all iterations\n",
    "        if ((iteration)%valid_steps)==0: #output loss with valid_K batchsize\n",
    "            summary, rate, valid_loss=sess.run([scope_train+'Merged/Merged:0',scope_train+'Learn_Rate:0', scope+'Losses/Loss:0'], feed_dict=valid_dictionary)\n",
    "            summary_acc, l2_err, max_err=sess.run(['Accuracy/Merged_Acc/Merged_Acc:0','Accuracy/L2-Error:0', 'Accuracy/Max-Error:0'], feed_dict=accuracy_dictionary)\n",
    "            writer[level-l_min].add_summary(summary, iteration) \n",
    "            writer[level-l_min].add_summary(summary_acc, iteration)  \n",
    "            print('Network: %d, Iteration: %d, Loss: %.8f, Max. Error: %.4f, L2-Error: %.4f, Learning Rate: %.1E' %(level,iteration,valid_loss,max_err,l2_err,rate))\n",
    "        sess.run(scope_train+'Minimizer:0', feed_dict={'Input/Is_Training:0': True, scope_target+'Is_Validation:0': False, 'Input/Network-Input/Batchsize:0': batch_sizes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the neuronal networks, initialize variables and prepare summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model build!\n",
      "Data for validation and accuracy measurements computed!\n",
      "Variables initialized!\n",
      "Tensorboard summaries prepared!\n"
     ]
    }
   ],
   "source": [
    "build_model()\n",
    "print('Model build!')\n",
    "valid_data, acc_data=valid_accuracy_data(n_valid,n_acc)\n",
    "print('Data for validation and accuracy measurements computed!')\n",
    "tf.global_variables_initializer().run() #initializiation of the variables\n",
    "print('Variables initialized!')\n",
    "count=0 #find a new directory for the summary logs\n",
    "while True:\n",
    "    count+=1\n",
    "    if not tf.gfile.Exists('logs/log'+str(count)):\n",
    "        dir='logs/log'+str(count)\n",
    "        break\n",
    "writer = [tf.summary.FileWriter(dir+'/network_'+str(l)) for l in range(l_min,l_max+1)] #write summaries (takes some time to execute)\n",
    "writer[0].add_graph(sess.graph) \n",
    "print('Tensorboard summaries prepared!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network: 0, Iteration: 0, Loss: 46553.92968750, Max. Error: 142.9282, L2-Error: 133.9649, Learning Rate: 1.0E-03\n",
      "Network: 0, Iteration: 500, Loss: 44830.26562500, Max. Error: 136.2139, L2-Error: 127.2600, Learning Rate: 9.9E-04\n",
      "Network: 0, Iteration: 1000, Loss: 42820.62109375, Max. Error: 127.9701, L2-Error: 118.9290, Learning Rate: 9.8E-04\n",
      "Network: 0, Iteration: 1500, Loss: 40844.11328125, Max. Error: 119.0546, L2-Error: 110.1335, Learning Rate: 9.7E-04\n",
      "Network: 0, Iteration: 2000, Loss: 39028.14062500, Max. Error: 110.2086, L2-Error: 101.3641, Learning Rate: 9.6E-04\n",
      "Network: 0, Iteration: 2500, Loss: 37398.22656250, Max. Error: 101.5493, L2-Error: 92.7330, Learning Rate: 9.5E-04\n",
      "Network: 0, Iteration: 3000, Loss: 36021.19140625, Max. Error: 93.5751, L2-Error: 84.7646, Learning Rate: 9.4E-04\n",
      "Network: 0, Iteration: 3500, Loss: 34825.08203125, Max. Error: 85.9648, L2-Error: 77.1582, Learning Rate: 9.3E-04\n",
      "Network: 0, Iteration: 4000, Loss: 33780.62109375, Max. Error: 78.6667, L2-Error: 69.8264, Learning Rate: 9.2E-04\n",
      "Network: 0, Iteration: 4500, Loss: 32890.92968750, Max. Error: 71.8259, L2-Error: 62.8621, Learning Rate: 9.1E-04\n",
      "Network: 0, Iteration: 5000, Loss: 32121.62304688, Max. Error: 65.0562, L2-Error: 56.1393, Learning Rate: 9.0E-04\n",
      "Network: 0, Iteration: 5500, Loss: 31497.18359375, Max. Error: 58.8659, L2-Error: 49.9886, Learning Rate: 9.0E-04\n",
      "Network: 0, Iteration: 6000, Loss: 30975.92968750, Max. Error: 52.9754, L2-Error: 44.1768, Learning Rate: 8.9E-04\n",
      "Network: 0, Iteration: 6500, Loss: 30528.44726562, Max. Error: 47.2664, L2-Error: 38.4036, Learning Rate: 8.8E-04\n",
      "Network: 0, Iteration: 7000, Loss: 30168.12500000, Max. Error: 41.8168, L2-Error: 33.0073, Learning Rate: 8.7E-04\n",
      "Network: 0, Iteration: 7500, Loss: 29897.47460938, Max. Error: 36.5569, L2-Error: 28.2611, Learning Rate: 8.6E-04\n",
      "Network: 0, Iteration: 8000, Loss: 29685.16406250, Max. Error: 32.3092, L2-Error: 23.7540, Learning Rate: 8.5E-04\n",
      "Network: 0, Iteration: 8500, Loss: 29511.50000000, Max. Error: 27.5554, L2-Error: 19.2327, Learning Rate: 8.4E-04\n",
      "Network: 0, Iteration: 9000, Loss: 29402.13476562, Max. Error: 23.7046, L2-Error: 15.5920, Learning Rate: 8.3E-04\n",
      "Network: 0, Iteration: 9500, Loss: 29343.67968750, Max. Error: 21.3731, L2-Error: 13.0865, Learning Rate: 8.3E-04\n",
      "Network: 0, Iteration: 10000, Loss: 29305.80468750, Max. Error: 17.7552, L2-Error: 11.0073, Learning Rate: 8.2E-04\n",
      "Network: 0, Iteration: 10500, Loss: 29260.62304688, Max. Error: 15.3870, L2-Error: 7.8535, Learning Rate: 8.1E-04\n",
      "Network: 0, Iteration: 11000, Loss: 29247.06250000, Max. Error: 13.3415, L2-Error: 6.3276, Learning Rate: 8.0E-04\n",
      "Network: 0, Iteration: 11500, Loss: 29243.41796875, Max. Error: 11.8179, L2-Error: 5.2472, Learning Rate: 7.9E-04\n",
      "Network: 0, Iteration: 12000, Loss: 29242.00976562, Max. Error: 10.7872, L2-Error: 4.4447, Learning Rate: 7.9E-04\n",
      "Network: 0, Iteration: 12500, Loss: 29241.94531250, Max. Error: 9.9635, L2-Error: 4.0994, Learning Rate: 7.8E-04\n",
      "Network: 0, Iteration: 13000, Loss: 29240.22460938, Max. Error: 9.7497, L2-Error: 3.8382, Learning Rate: 7.7E-04\n",
      "Network: 0, Iteration: 13500, Loss: 29243.25781250, Max. Error: 9.1686, L2-Error: 3.6930, Learning Rate: 7.6E-04\n",
      "Network: 0, Iteration: 14000, Loss: 29243.68945312, Max. Error: 8.9646, L2-Error: 3.5732, Learning Rate: 7.5E-04\n",
      "Network: 0, Iteration: 14500, Loss: 29242.59570312, Max. Error: 8.9895, L2-Error: 3.5604, Learning Rate: 7.5E-04\n",
      "Network: 0, Iteration: 15000, Loss: 29245.30468750, Max. Error: 8.7861, L2-Error: 3.6214, Learning Rate: 7.4E-04\n",
      "Network: 0, Iteration: 15500, Loss: 29246.16992188, Max. Error: 8.5780, L2-Error: 3.6467, Learning Rate: 7.3E-04\n",
      "Network: 0, Iteration: 16000, Loss: 29248.77734375, Max. Error: 9.1473, L2-Error: 3.7942, Learning Rate: 7.2E-04\n",
      "Network: 0, Iteration: 16500, Loss: 29248.41992188, Max. Error: 9.5991, L2-Error: 3.8634, Learning Rate: 7.2E-04\n",
      "Network: 0, Iteration: 17000, Loss: 29244.96093750, Max. Error: 8.7050, L2-Error: 3.6410, Learning Rate: 7.1E-04\n",
      "Network: 0, Iteration: 17500, Loss: 29244.57617188, Max. Error: 8.9333, L2-Error: 3.7289, Learning Rate: 7.0E-04\n",
      "Network: 0, Iteration: 18000, Loss: 29243.12304688, Max. Error: 9.7082, L2-Error: 3.7307, Learning Rate: 7.0E-04\n",
      "Network: 0, Iteration: 18500, Loss: 29243.48242188, Max. Error: 9.0533, L2-Error: 3.6170, Learning Rate: 6.9E-04\n",
      "Network: 0, Iteration: 19000, Loss: 29244.29687500, Max. Error: 8.8614, L2-Error: 3.5448, Learning Rate: 6.8E-04\n",
      "Network: 0, Iteration: 19500, Loss: 29243.75390625, Max. Error: 8.7470, L2-Error: 3.5387, Learning Rate: 6.8E-04\n",
      "Network: 0, Iteration: 20000, Loss: 29245.49023438, Max. Error: 8.3916, L2-Error: 3.4402, Learning Rate: 6.7E-04\n",
      "Network: 0, Iteration: 20500, Loss: 29247.50390625, Max. Error: 8.8859, L2-Error: 3.6623, Learning Rate: 6.6E-04\n",
      "Network: 0, Iteration: 21000, Loss: 29247.80859375, Max. Error: 8.9999, L2-Error: 3.8055, Learning Rate: 6.6E-04\n",
      "Network: 0, Iteration: 21500, Loss: 29246.82226562, Max. Error: 8.5758, L2-Error: 3.6456, Learning Rate: 6.5E-04\n",
      "Network: 0, Iteration: 22000, Loss: 29249.84960938, Max. Error: 9.9716, L2-Error: 3.9861, Learning Rate: 6.4E-04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-1cc84d3f59cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_min\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml_max\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrainNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_max\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ml_min\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#K\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Elapsed minutes to train the networks: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-156-88f780fbdeff>\u001b[0m in \u001b[0;36mtrainNN\u001b[1;34m(level, n_iterations, validation_data, accuracy_data, batch_sizes)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mglob_iterations\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#for all iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#output loss with valid_K batchsize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscope_train\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'Merged/Merged:0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscope_train\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'Learn_Rate:0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'Losses/Loss:0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_dictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[0msummary_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_err\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Accuracy/Merged_Acc/Merged_Acc:0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Accuracy/L2-Error:0'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Accuracy/Max-Error:0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccuracy_dictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml_min\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iter=40000 #number of gradient descents\n",
    "start = timer()\n",
    "for l in range(l_min,l_max+1):    \n",
    "    trainNN(l,n_iter,valid_data,acc_data,128*2**(l_max+l_min-l)) #K\n",
    "end = timer()\n",
    "print('Elapsed minutes to train the networks: ',(end - start)/60)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Train further selected networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=0\n",
    "n_iter=5000\n",
    "batch_sz=1000 #K*2**(l_max+l_min-level)\n",
    "trainNN(l,n_iter,valid_data,acc_data,batch_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy against analytic solution (only for mu=0!!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_value(X):\n",
    "    sigma_matrix=np.transpose(sess.run('PDE-Parameter/Sigma:0'))\n",
    "    return (np.sum(X**2,axis=1,keepdims=True)+T*np.trace(sigma_matrix@np.transpose(sigma_matrix)))\n",
    "\n",
    "def max_l2_analytic_error(n_tests): \n",
    "    dictionary={'Input/Is_Training:0': True, 'Input/Network-Input/Batchsize:0': n_tests}\n",
    "    xi=sess.run('Input/Network-Input/Merge:0',feed_dict=dictionary)\n",
    "    del dictionary['Input/Network-Input/Batchsize:0']\n",
    "    real_u=real_value(xi)\n",
    "    dictionary.update({'Input/Network-Input/X-Input:0': xi, 'Input/Is_Training:0': False, 'Accuracy/U_Real:0': real_u})\n",
    "    max_error, l2_error=sess.run(['Accuracy/Max-Error:0','Accuracy/L2-Error:0'],feed_dict=dictionary)\n",
    "    return max_error, l2_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy against (Multilevel) Montecarlo sampling (and actual solution if mu=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. Error: 15.5524 L2_Error: 2.6893\n"
     ]
    }
   ],
   "source": [
    "max_analytic, l2_analytic=max_l2_analytic_error(500000)\n",
    "print('Max. Error: %.4f L2_Error: %.4f' %(max_analytic,l2_analytic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_eval(X):\n",
    "    return sess.run('Accuracy/U_Approximation:0', feed_dict={'Input/Network-Input/X-Input:0': X, 'Input/Is_Training:0': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test:  1 , x= [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]] \n",
      "\n",
      "Real value (only for mu=0):  [[199.99993134]]\n",
      "Neuronal Network approx.:    [[133.75131]]\n",
      "\n",
      " test:  2 , x= [[0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]] \n",
      "\n",
      "Real value (only for mu=0):  [[100.03993134]]\n",
      "Neuronal Network approx.:    [[126.71176]]\n",
      "\n",
      " test:  3 , x= [[0.28872775 0.84648324 0.12352756 0.10981383 0.17822633 0.67622584\n",
      "  0.31617769 0.31943787 0.28903438 0.97756499 0.33338639 0.90041224\n",
      "  0.50453979 0.23805724 0.26388051 0.64013116 0.10693902 0.86915081\n",
      "  0.97321226 0.02960873 0.88968433 0.46742227 0.26783538 0.50639916\n",
      "  0.3096063  0.31842256 0.39682381 0.94502717 0.45425102 0.44748232\n",
      "  0.73946971 0.18620815 0.918329   0.8856256  0.03284609 0.9330002\n",
      "  0.19038681 0.69214215 0.85249032 0.4508878  0.05004361 0.90749626\n",
      "  0.53709948 0.43011049 0.72777384 0.93232688 0.99730951 0.33254767\n",
      "  0.44246549 0.17611991 0.76385789 0.88791174 0.16936061 0.12295734\n",
      "  0.48746447 0.76383832 0.92144857 0.05997293 0.19161871 0.21700702\n",
      "  0.5792662  0.96568956 0.67474809 0.91047064 0.40693937 0.93032316\n",
      "  0.23499713 0.38573608 0.00136997 0.17642848 0.60176741 0.32136151\n",
      "  0.39053285 0.96267966 0.41740603 0.01876367 0.55723798 0.71835559\n",
      "  0.55315723 0.85602116 0.0852032  0.74822124 0.87366933 0.05209161\n",
      "  0.03743818 0.88792494 0.26698802 0.2822365  0.53491275 0.94017266\n",
      "  0.76090351 0.39162165 0.29027415 0.9981471  0.30881399 0.44352992\n",
      "  0.53283263 0.60308042 0.53510277 0.62904877]] \n",
      "\n",
      "Real value (only for mu=0):  [[134.98874488]]\n",
      "Neuronal Network approx.:    [[133.85986]]\n",
      "\n",
      " test:  4 , x= [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Real value (only for mu=0):  [[99.99993134]]\n",
      "Neuronal Network approx.:    [[126.709946]]\n",
      "\n",
      " test:  5 , x= [[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      "  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      "  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      "  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      "  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      "  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]] \n",
      "\n",
      "Real value (only for mu=0):  [[100.99993134]]\n",
      "Neuronal Network approx.:    [[126.735245]]\n",
      "\n",
      " test:  6 , x= [[0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2\n",
      "  0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2\n",
      "  0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2\n",
      "  0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2\n",
      "  0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2\n",
      "  0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2]] \n",
      "\n",
      "Real value (only for mu=0):  [[103.99993134]]\n",
      "Neuronal Network approx.:    [[126.7962]]\n",
      "\n",
      " test:  7 , x= [[0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      "  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      "  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      "  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      "  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3\n",
      "  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3]] \n",
      "\n",
      "Real value (only for mu=0):  [[108.99993134]]\n",
      "Neuronal Network approx.:    [[127.01747]]\n",
      "\n",
      " test:  8 , x= [[0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4\n",
      "  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4\n",
      "  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4\n",
      "  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4\n",
      "  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4\n",
      "  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]] \n",
      "\n",
      "Real value (only for mu=0):  [[115.99993134]]\n",
      "Neuronal Network approx.:    [[128.49869]]\n",
      "\n",
      " test:  9 , x= [[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      "  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      "  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      "  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      "  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      "  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]] \n",
      "\n",
      "Real value (only for mu=0):  [[124.99993134]]\n",
      "Neuronal Network approx.:    [[133.97466]]\n",
      "\n",
      " test:  10 , x= [[0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6\n",
      "  0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6\n",
      "  0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6\n",
      "  0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6\n",
      "  0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6\n",
      "  0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6]] \n",
      "\n",
      "Real value (only for mu=0):  [[135.99993134]]\n",
      "Neuronal Network approx.:    [[133.76344]]\n",
      "\n",
      " test:  11 , x= [[1.         0.5        0.33333333 0.25       0.2        0.16666667\n",
      "  0.14285714 0.125      0.11111111 0.1        0.09090909 0.08333333\n",
      "  0.07692308 0.07142857 0.06666667 0.0625     0.05882353 0.05555556\n",
      "  0.05263158 0.05       0.04761905 0.04545455 0.04347826 0.04166667\n",
      "  0.04       0.03846154 0.03703704 0.03571429 0.03448276 0.03333333\n",
      "  0.03225806 0.03125    0.03030303 0.02941176 0.02857143 0.02777778\n",
      "  0.02702703 0.02631579 0.02564103 0.025      0.02439024 0.02380952\n",
      "  0.02325581 0.02272727 0.02222222 0.02173913 0.0212766  0.02083333\n",
      "  0.02040816 0.02       0.01960784 0.01923077 0.01886792 0.01851852\n",
      "  0.01818182 0.01785714 0.01754386 0.01724138 0.01694915 0.01666667\n",
      "  0.01639344 0.01612903 0.01587302 0.015625   0.01538462 0.01515152\n",
      "  0.01492537 0.01470588 0.01449275 0.01428571 0.01408451 0.01388889\n",
      "  0.01369863 0.01351351 0.01333333 0.01315789 0.01298701 0.01282051\n",
      "  0.01265823 0.0125     0.01234568 0.01219512 0.01204819 0.01190476\n",
      "  0.01176471 0.01162791 0.01149425 0.01136364 0.01123596 0.01111111\n",
      "  0.01098901 0.01086957 0.01075269 0.0106383  0.01052632 0.01041667\n",
      "  0.01030928 0.01020408 0.01010101 0.01      ]] \n",
      "\n",
      "Real value (only for mu=0):  [[101.63491524]]\n",
      "Neuronal Network approx.:    [[126.70396]]\n",
      "\n",
      " test:  12 , x= [[0.62453044 0.65999951 0.18968809 0.2318719  0.13091934 0.51045865\n",
      "  0.25633241 0.90946398 0.21724048 0.96822369 0.49170919 0.23297209\n",
      "  0.57996175 0.61842035 0.21039035 0.68684891 0.08741003 0.61830388\n",
      "  0.58075204 0.81562033 0.79144326 0.69793932 0.32040038 0.18079221\n",
      "  0.55318584 0.65842939 0.44693866 0.48143612 0.06563171 0.47125748\n",
      "  0.99183609 0.27135891 0.11451042 0.8665895  0.41733141 0.49252622\n",
      "  0.07162527 0.66019269 0.80416256 0.23722449 0.51583043 0.4475985\n",
      "  0.49300627 0.08623062 0.69266516 0.8590432  0.16912256 0.10563358\n",
      "  0.16061606 0.98819182 0.89430744 0.79607689 0.5344728  0.48780658\n",
      "  0.72300563 0.86332894 0.22696204 0.68542038 0.93972281 0.04679357\n",
      "  0.16855432 0.05290302 0.41272914 0.24164144 0.94065187 0.36251826\n",
      "  0.17839101 0.69999079 0.01586601 0.07420464 0.24536946 0.69918505\n",
      "  0.33142821 0.64071439 0.17700305 0.54994215 0.65860487 0.87673703\n",
      "  0.21750437 0.9039185  0.19805698 0.86952047 0.74101525 0.2700594\n",
      "  0.22894224 0.06550695 0.55730123 0.77609562 0.32427736 0.32111224\n",
      "  0.16352792 0.86047378 0.11258282 0.6979575  0.03792895 0.70888455\n",
      "  0.38759261 0.59857956 0.12063447 0.32472089]] \n",
      "\n",
      "Real value (only for mu=0):  [[129.8992523]]\n",
      "Neuronal Network approx.:    [[133.44553]]\n"
     ]
    }
   ],
   "source": [
    "x_0=np.zeros((1,d))\n",
    "x_0[0,0]=0.2\n",
    "tests=[np.ones((1,d)),x_0,np.random.uniform(a,b,(1,d)),np.zeros((1,d)),0.1*np.ones((1,d)),0.2*np.ones((1,d)),0.3*np.ones((1,d)),0.4*np.ones((1,d)),0.5*np.ones((1,d)),0.6*np.ones((1,d)),np.array([np.arange(1,d+1,1)**(-1.0)]),np.random.uniform(a,b,(1,d))]\n",
    "for count, test in enumerate(tests, start=1):\n",
    "    print('\\n test: ',count,', x=',test,'\\n')\n",
    "    print('Real value (only for mu=0): ',real_value(test))\n",
    "    #print('Monte-Carlo:                ',Montecarlosampling(5000,test))\n",
    "    #print('Multilevel Monte-Carlo:     ',MLMontecarlosampling(128,test))\n",
    "    print('Neuronal Network approx.:   ',u_eval(test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Plot the solution (if d=1 or d=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if d==1:\n",
    "    import matplotlib.pyplot as plt\n",
    "    X=np.arange(a, b, 0.01)\n",
    "    Y=eval_u(np.transpose(np.array([X])))\n",
    "    plt.plot(X,Y, 'r')\n",
    "    plt.show()\n",
    "if d==2:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    fig=plt.figure()\n",
    "    ax=fig.gca(projection='3d')\n",
    "    n=20\n",
    "    X,Y=np.meshgrid(np.arange(a, b, (b-a)/n), np.arange(a, b, (b-a)/n))\n",
    "    Z=np.zeros(X.shape)\n",
    "    Z_sol=np.zeros(X.shape)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            Z[i,j]=eval_u(np.array([[X[i,j],Y[i,j]]]))\n",
    "            Z_sol[i,j]=real_value(np.array([[X[i,j],Y[i,j]]]))\n",
    "    ax.plot_surface(X, Y, Z)\n",
    "    ax.plot_surface(X, Y, Z_sol)\n",
    "    plt.show()\n",
    "    print('Neural Network Approx.: Blue, Exact Solution: Orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Show the Neuronal networks and Summaries on tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=\"logs\" --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now open: http://localhost:6006/ or http://PC-NAME:6006/ (z.B.: http://Julius-PC:6006/) restart the kernel afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1.]])], array([[100.97367859]])]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary={'Input/Is_Training:0': True, 'Input/Network-Input/Batchsize:0': 1}\n",
    "#accuracy_data=[sess.run('Input/Network-Input/Merge:0',feed_dict=dictionary)]\n",
    "#dictionary['Input/Network-Input/Batchsize:0']=num_validation\n",
    "dictionary=dict()\n",
    "num_accuracy=1\n",
    "accuracy_data=[[np.ones((1,d))]]\n",
    "dictionary.update({'Network_'+str(l)+'/Target/Is_Validation:0': False for l in range(l_min,l_max+1)})\n",
    "#fetch=['Input/Network-Input/Merge:0']\n",
    "#fetch.append(['Network_'+str(l)+'/Target/Network-Target/Merge:0' for l in range(l_min,l_max+1)])\n",
    "#validation_data=sess.run(fetch,feed_dict=dictionary)\n",
    "dictionary['Input/Is_Training:0']=False    \n",
    "#del dictionary['Input/Network-Input/Batchsize:0']\n",
    "MC_mean=np.empty((num_accuracy,1))\n",
    "for sample in range(num_accuracy):\n",
    "    dictionary.update({'Input/Network-Input/X-Input:0': np.tile(accuracy_data[0][sample],(100000,1))})\n",
    "    MC_mean[sample]=sess.run('Accuracy/U_MC_Mean:0',feed_dict=dictionary)    \n",
    "accuracy_data.append(MC_mean)\n",
    "accuracy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
